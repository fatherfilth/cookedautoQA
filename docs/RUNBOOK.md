# Alert Triage Runbook

## When to Use This Runbook

**Trigger:** You received a Slack alert from the `Playwright Monitoring` GitHub Actions workflow.

**Alert threshold:** Notifications are sent after 2+ consecutive failures (reduces noise from transient issues).

**Alerts appear in:** Channel configured via `SLACK_WEBHOOK_URL` (check with team for specific channel)

## Alert Anatomy

Slack messages include:

- **Severity level:** `CRITICAL` or `WARNING`
- **Failed test names:** List of tests that failed with consecutive failure counts (e.g., "3x consecutive")
- **Error snippets:** First 100 characters of error messages
- **GitHub Actions run link:** Direct link to workflow execution
- **Artifacts link:** Direct link to HTML reports and traces

**Source:** Generated by `scripts/notify-slack.js` after parsing Playwright JSON results.

## Severity Levels

| Tag | Meaning | Test Categories | Response Time | Escalation |
|-----|---------|-----------------|---------------|------------|
| `@critical` | Revenue-impacting flows broken | Auth (login, registration, session), Games (slot/table/live dealer launch), Crypto (Swapped.com buy flow) | Investigate immediately | Page on-call if site-wide issue |
| `@warning` | Non-critical features degraded | Smoke (homepage, navigation, lobby, search), Social (chat, tipping, promotions) | Investigate within 4 hours | Notify team in Slack, no page |

**Consecutive failure threshold:** Alerts only fire after 2+ consecutive failures. Single failures are tracked but don't trigger alerts.

## Triage Checklist

Follow these steps in order when receiving an alert:

### Step 1: Open GitHub Actions Run

- [ ] Click the GitHub Actions run link from the Slack alert
- [ ] Check workflow status (running, completed, failed)
- [ ] Note timestamp - is this a one-time failure or recurring pattern?

### Step 2: Determine Scope

- [ ] Review failed test count from Slack message
- [ ] Check if multiple unrelated tests failed (site-wide) or single test (isolated)
- [ ] Note severity - all `@critical`, all `@warning`, or mixed?

### Step 3: Download and Review Artifacts

- [ ] Click "Artifacts" link from Slack message (or navigate to GitHub Actions run > Artifacts section)
- [ ] Download `playwright-report` artifact (HTML report with screenshots/traces)
- [ ] Extract and open locally:
   ```bash
   npx playwright show-report <extracted-folder>
   ```
- [ ] For each failed test in report:
  - View screenshot (page state at failure)
  - Open trace (full timeline of actions)

### Step 4: Analyze Error Patterns

- [ ] Review error messages in Playwright report
- [ ] Check trace timeline for:
  - Network request failures
  - Element not found errors
  - Timeout errors
  - WebSocket connection issues
- [ ] Compare with "Common False Positives" section below

### Step 5: Determine Root Cause

Use this decision table:

| Symptom | Likely Cause | Action |
|---------|--------------|--------|
| Multiple unrelated tests fail | Site down/slow or auth system down | Check cooked.com manually, escalate immediately |
| Single test fails consistently | Feature changed or test broken | Create GitHub issue, investigate during business hours |
| Login/auth tests fail | Credentials expired or auth service down | Verify test user account, check auth manually |
| Game launch tests fail | Provider iframe timeout (third-party) | Check game manually on site, may be provider outage |
| Chat/social tests fail | Chat service degraded | Check manually, likely non-critical (follow WARNING SLA) |
| Test fails once then passes on retry | Flaky test (below threshold) | Monitor, create issue if recurring |

### Step 6: Take Action

Based on severity and root cause:

- [ ] **Site-wide `@critical` failure:** Page on-call engineer via PagerDuty, post in `#incidents` Slack
- [ ] **Single `@critical` test (3+ consecutive failures):** Notify dev team lead in `#dev-team`, investigate within 1 hour
- [ ] **`@warning` failures:** Notify QA team in `#qa-alerts`, investigate within 4 hours
- [ ] **Known false positive:** Acknowledge alert, document below if new pattern
- [ ] **Unclear/new pattern:** Post in `#test-automation` with trace link, ask test automation lead

## Root Cause Decision Table

Detailed decision logic:

| Symptom | Root Cause | Evidence in Trace | Action | Urgency |
|---------|------------|-------------------|--------|---------|
| 3+ auth, game, and crypto tests fail | Site down or extremely slow | Network timeouts, 5xx errors, page.goto failures | Manually verify cooked.com loads, escalate to on-call | Immediate |
| Only login/registration tests fail | Auth system down or credentials expired | 401/403 responses, "invalid credentials" errors | Check test user account, verify auth endpoint manually | Immediate |
| Single game test fails (e.g., only slots) | Game provider issue (third-party) | iframe timeout, no network response from provider domain | Test game manually on cooked.com, check if provider-wide | 1 hour (if manual test works, likely provider blip) |
| Chat connection test fails | WebSocket service degraded | WebSocket connection timeout, no "open" event | Check chat manually, verify WebSocket endpoint | 4 hours (non-critical) |
| Session persistence test fails intermittently | Flaky test (timing race condition) | Cookies set correctly, assertion timeout | Known issue, monitor frequency | No action if <10% failure rate |
| Search test fails | Search API down or UI changed | 500 error from search API, or element not found | Check search manually, verify API status | 4 hours (non-critical) |

## Common False Positives

Document known flaky patterns to reduce noise:

### 1. WebSocket Connection Timeout in Chat Tests

**Symptom:** `tests/social/chat-connection.spec.ts` fails with "WebSocket did not connect within 10s"

**Why it's false positive:** Chat service occasionally slow during off-peak hours; resolves on retry

**How to recognize:**
- Only chat tests fail, not auth or game tests
- Happens during low-traffic hours (2-6 AM UTC)
- Next scheduled run passes
- Trace shows WebSocket handshake delayed but eventually succeeds on retry

**Action:** Acknowledge alert, no escalation needed. If persists 3+ consecutive runs, escalate to dev team.

### 2. Game Iframe Load Timeout

**Symptom:** `tests/game/slot-launch.spec.ts`, `table-launch.spec.ts`, or `live-dealer-launch.spec.ts` fail with "iframe did not load within 30s"

**Why it's false positive:** Third-party game providers (NetEnt, Evolution, etc.) occasionally slow; not cooked.com issue

**How to recognize:**
- Single game provider fails (e.g., only slots, not table games)
- Playwright trace shows network request to provider domain (e.g., `netent.com`) hung or very slow
- Other tests (auth, lobby navigation) pass
- Iframe `src` points to third-party domain

**Action:** Verify game loads manually on cooked.com. If manual test works, likely provider blip. Acknowledge alert. If all game types fail, escalate (may indicate cooked.com issue).

### 3. Session Persistence Flake

**Symptom:** `tests/auth/session-persistence.spec.ts` fails intermittently with "Expected to be logged in after reload"

**Why it's false positive:** Test relies on cookie timing; occasionally hits race condition between cookie save and page reload

**How to recognize:**
- Fails <10% of runs
- Trace shows cookies set correctly in storage state
- Login flow succeeded, but assertion on reloaded page timed out
- Retry passes

**Action:** Known flaky test (logged as issue - check GitHub issues for tracking). Acknowledge alert. Fix planned: add explicit wait for auth state after reload.

### 4. Network Timeout on First Test of Suite (Cold Start)

**Symptom:** First test in any category occasionally fails with "page.goto: Timeout 30000ms exceeded"

**Why it's false positive:** CI environment cold start - first network request is slower

**How to recognize:**
- Only first test in workflow run fails
- Subsequent tests in same run pass
- Trace shows very long initial connection time (>20s)
- Happens more frequently on scheduled runs (after 30 min idle)

**Action:** Acknowledge alert. If recurring frequently, consider adding warmup request before test suite.

## Escalation Paths

Clear escalation matrix based on scenario:

| Scenario | Notify | Channel/Method | Urgency | SLA |
|----------|--------|----------------|---------|-----|
| Multiple `@critical` tests fail (site-wide) | On-call engineer | PagerDuty page + `#incidents` Slack | Immediate | 5 min response |
| Single `@critical` test fails 3+ times | Dev team lead | `#dev-team` Slack | High | 1 hour |
| All `@warning` tests fail | QA team | `#qa-alerts` Slack | Medium | 4 hours |
| Mixed `@critical` and `@warning` | Dev team lead | `#dev-team` Slack | High | 1 hour |
| All tests pass after 1-2 retries | No one (expected) | N/A | N/A | No action |
| Unknown/new failure pattern | Test automation lead | `#test-automation` Slack | Low | Next business day |
| Suspected test issue (not site issue) | Test automation lead | GitHub issue + `#test-automation` | Low | Next business day |

**Reference links:**
- On-call rotation: [PagerDuty schedule link - add your team's link]
- Incident response: `#incidents` Slack channel
- Dev escalation: `#dev-team` Slack channel
- QA alerts: `#qa-alerts` Slack channel
- Test automation: `#test-automation` Slack channel

## Quick Actions

Copy-pasteable commands for common triage tasks:

### Re-run Failed Test Locally with Trace

```bash
# Set up environment (copy from .env or GitHub Secrets)
export BASE_URL=https://cooked.com
export TEST_USER_EMAIL=your-test-user@example.com
export TEST_USER_PASSWORD=your-password

# Run specific failed test with trace enabled
npx playwright test tests/auth/login.spec.ts --trace on

# View trace (path shown in test output)
npx playwright show-trace test-results/<test-name>/trace.zip
```

### Download and View CI Artifacts

```bash
# 1. Download artifacts from GitHub Actions UI:
#    - Navigate to workflow run
#    - Click "Artifacts" (top right)
#    - Download playwright-report.zip and test-results.zip

# 2. Extract and view HTML report
npx playwright show-report playwright-report/

# 3. View specific test trace
npx playwright show-trace test-results/<test-name>/trace.zip
```

### Check Consecutive Failure State

```bash
# View current failure tracking state (shows failure count per test)
cat .state/failure-state.json

# Each entry shows:
# {
#   "test-name": {
#     "count": 2,
#     "lastFailure": "2026-02-16T10:30:00.000Z"
#   }
# }
# Threshold is 2 consecutive failures for alerting
```

### Manually Trigger Workflow

```bash
# Requires GitHub CLI (gh) installed and authenticated
gh workflow run playwright.yml

# Or via GitHub UI:
# Actions > Playwright Monitoring > Run workflow button (right side)
```

### View Recent Workflow Runs

```bash
# Requires GitHub CLI
gh run list --workflow=playwright.yml --limit 10

# Shows recent run status, timing, and links
```

## Contacts

**Key roles for escalation:**

- **Dev Team Lead:** @dev-lead (Slack) / dev-lead@example.com
- **QA Lead:** @qa-lead (Slack) / qa-lead@example.com
- **Test Automation Lead:** @test-automation-lead (Slack) / test-automation@example.com
- **On-Call Engineer:** PagerDuty escalation policy "Production Alerts" [add link]

**Update these placeholders with actual team member names/handles.**

## Workflow Reference

**GitHub Actions workflow:** [.github/workflows/playwright.yml](../.github/workflows/playwright.yml)

**Schedule:** Every 30 minutes (UTC) via cron: `*/30 * * * *`

**Additional triggers:**
- Push to `main` branch
- Manual workflow dispatch

**Slack notification logic:** [scripts/notify-slack.js](../scripts/notify-slack.js)

**Artifact retention:**
- `playwright-report`: 30 days
- `test-results` (traces, screenshots): 7 days

## Runbook Maintenance

**Last updated:** 2026-02-16 (Phase 6 - Documentation & Polish)

**Review schedule:**
- After every major incident that exposes gaps in runbook
- Quarterly review (every 3 months)
- When test suite structure changes significantly

**Owner:** Test Automation Team

**Improvement process:**
1. Document new false positive patterns as they're discovered
2. Update escalation paths when team structure changes
3. Add new common failure patterns from incident retrospectives
4. Update contact info when on-call rotation changes

**Version history:**
- v1.0 (2026-02-16): Initial runbook created for Phase 6
